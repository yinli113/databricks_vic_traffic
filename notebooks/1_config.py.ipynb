{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c427c586-0360-4191-a592-8f7bdd58bc9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Central configuration for the traffic ETL pipeline.\n",
    "\n",
    "This module defines a single ``Config`` class that centralizes all\n",
    "catalog names, database names and storage locations used in the ETL\n",
    "process.  The ``conf`` object is provided as a convenient singleton\n",
    "instance.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Central configuration for the traffic ETL pipeline.\n",
    "(Only change here: add REGION_MAP for dim_region build.)\n",
    "\"\"\"\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Optional: region map if you seed dim_region elsewhere\n",
    "REGION_MAP = {\n",
    "    \"BBN\": \"Blackburn\", \"BEN\": \"Bendigo\", \"BRI\": \"Brighton\", \"CA1\": \"Carlton 1\", \"CA2\": \"Carlton 2\",\n",
    "    \"CRN\": \"Croydon\", \"DIO\": \"Dialin/Dialout (remote)\", \"DON\": \"Doncaster\", \"DUP\": \"Duplicate\",\n",
    "    \"ES2\": \"Essendon 2\", \"ESS\": \"Essendon\", \"FR2\": \"Frankston 2\", \"FRA\": \"Frankston\",\n",
    "    \"FT1\": \"Footscray 1\", \"FT2\": \"Footscray 2\", \"FT3\": \"Footscray 3\", \"GE2\": \"Geelong 2\",\n",
    "    \"GEE\": \"Geelong\", \"GLI\": \"Glen Iris\", \"GR2\": \"Greensborough 2\", \"GRE\": \"Greensborough\",\n",
    "    \"KEW\": \"Kew\", \"MC1\": \"Melbourne City 1\", \"MC2\": \"Melbourne City 2\", \"MC3\": \"Melbourne City 3\",\n",
    "    \"MEN\": \"Mentone\", \"MNP\": \"Moonee Ponds\", \"PR2\": \"Preston 2\", \"PRS\": \"Preston\",\n",
    "    \"SK1\": \"St Kilda 1\", \"SK2\": \"St Kilda 2\", \"SP2\": \"Springvale 2\", \"SPR\": \"Springvale\",\n",
    "    \"VI2\": \"Regional Victoria 2\", \"VIC\": \"Regional Victoria\", \"WV1\": \"Waverly 1\", \"WV2\": \"Waverly 2\"\n",
    "}\n",
    "\n",
    "# ---------------- Databricks widgets passthrough ----------------\n",
    "try:\n",
    "    dbutils.widgets.dropdown(\"ENV\", \"dev\", [\"dev\", \"qa\"], \"Environment\")\n",
    "    dbutils.widgets.text(\"STORAGE_ACCOUNT\", \"trafficsa2\", \"Storage account\")\n",
    "    dbutils.widgets.text(\"METASTORE_ACCOUNT\", \"trafficsa2\", \"Metastore account\")\n",
    "    os.environ[\"ENV\"] = dbutils.widgets.get(\"ENV\").strip().lower()\n",
    "    os.environ[\"STORAGE_ACCOUNT\"] = dbutils.widgets.get(\"STORAGE_ACCOUNT\").strip()\n",
    "    os.environ[\"METASTORE_ACCOUNT\"] = (dbutils.widgets.get(\"METASTORE_ACCOUNT\") or os.environ[\"STORAGE_ACCOUNT\"]).strip()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, env=None, storage_account=None, metastore_account=None):\n",
    "        # 1) resolve environment (widgets or env vars can set these before import)\n",
    "        self.env = (env or os.getenv(\"ENV\") or \"dev\").strip().lower()\n",
    "        sa = (storage_account   or os.getenv(\"STORAGE_ACCOUNT\")   or \"trafficsa2\").strip()\n",
    "        ms = (metastore_account or os.getenv(\"METASTORE_ACCOUNT\") or sa).strip()\n",
    "\n",
    "        # 2) UC names\n",
    "        self.catalog = self.env\n",
    "        self.db_name = \"traffic_db\"\n",
    "\n",
    "        # 3) FQDNs\n",
    "        self.sa_fqdn = f\"{sa}.dfs.core.windows.net\"\n",
    "        self.ms_fqdn = f\"{ms}.dfs.core.windows.net\"\n",
    "\n",
    "        # 4) storage locations\n",
    "        self.metastore_root  = f\"abfss://traffic-metastore-root@{self.ms_fqdn}/\"\n",
    "        self.managed_data    = f\"abfss://traffic-managed-{self.env}@{self.sa_fqdn}/\"\n",
    "        self.unmanaged_data  = f\"abfss://traffic-unmanaged-{self.env}@{self.sa_fqdn}/\"\n",
    "\n",
    "        # 5) base paths\n",
    "        self.raw_data_path   = f\"{self.unmanaged_data}data_zone\"\n",
    "        self.checkpoint_base = f\"{self.unmanaged_data}checkpoint_zone\"\n",
    "\n",
    "        # 6) logical table names (canonical)\n",
    "        self.bronze_table  = \"raw_traffic\"\n",
    "        self.silver_table  = \"traffic_silver_events\"   # canonical (plural)\n",
    "        self.region_lookup = \"region_lookup\"\n",
    "\n",
    "    def table_fqn(self, table: str) -> str:\n",
    "        return f\"{self.catalog}.{self.db_name}.{table}\"\n",
    "\n",
    "# default instance; will use ENV/STORAGE_ACCOUNT/METASTORE_ACCOUNT if set\n",
    "conf = Config()\n",
    "\n",
    "\n",
    "# optimize the spark session\n",
    "spark = SparkSession.getActiveSession() or SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"64\")\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"134217728\")\n",
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"true\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6512397025442030,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1_config.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
